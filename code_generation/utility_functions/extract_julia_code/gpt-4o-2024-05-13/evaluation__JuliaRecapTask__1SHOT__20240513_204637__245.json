{"name":"extract_julia_code","parsed":true,"executed":true,"unit_tests_count":5,"examples_count":4,"unit_tests_passed":0,"examples_executed":0,"tokens":[337,350],"elapsed_seconds":4.0421005,"cost":0.0,"model":"gpt-4o-2024-05-13","timestamp":"20240513_204637__245","prompt_strategy":"1SHOT","prompt_label":"JuliaRecapTask","device":"Apple-MacBook-Pro-M1","version_prompt":"1.1","schema":"PromptingTools.OpenAISchema()","version_pt":"0.17.1","parameters":{},"experiment":""}
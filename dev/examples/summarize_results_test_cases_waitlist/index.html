<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Results by Test Cases - WAITLIST · JuliaLLMLeaderboard.jl</title><meta name="title" content="Results by Test Cases - WAITLIST · JuliaLLMLeaderboard.jl"/><meta property="og:title" content="Results by Test Cases - WAITLIST · JuliaLLMLeaderboard.jl"/><meta property="twitter:title" content="Results by Test Cases - WAITLIST · JuliaLLMLeaderboard.jl"/><meta name="description" content="Documentation for JuliaLLMLeaderboard.jl."/><meta property="og:description" content="Documentation for JuliaLLMLeaderboard.jl."/><meta property="twitter:description" content="Documentation for JuliaLLMLeaderboard.jl."/><meta property="og:url" content="https://svilupp.github.io/Julia-LLM-Leaderboard/examples/summarize_results_test_cases_waitlist/"/><meta property="twitter:url" content="https://svilupp.github.io/Julia-LLM-Leaderboard/examples/summarize_results_test_cases_waitlist/"/><link rel="canonical" href="https://svilupp.github.io/Julia-LLM-Leaderboard/examples/summarize_results_test_cases_waitlist/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">JuliaLLMLeaderboard.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../getting_started/">Getting Started</a></li><li><a class="tocitem" href="../../methodology/">Methodology</a></li><li><a class="tocitem" href="../../test_definitions/">Test Definitions</a></li><li><span class="tocitem">Results</span><ul><li><a class="tocitem" href="../summarize_results_paid/">Paid APIs</a></li><li><a class="tocitem" href="../summarize_results_local/">Local Models</a></li><li><a class="tocitem" href="../compare_paid_vs_local/">Paid vs Local Models</a></li><li><a class="tocitem" href="../summarize_results_prompts/">By Prompts</a></li><li><a class="tocitem" href="../summarize_results_test_cases/">By Test Case</a></li></ul></li><li><a class="tocitem" href="../../frequently_asked_questions/">F.A.Q.</a></li><li><a class="tocitem" href="../../reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Results by Test Cases - WAITLIST</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Results by Test Cases - WAITLIST</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/svilupp/Julia-LLM-Leaderboard" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/svilupp/Julia-LLM-Leaderboard/blob/main/examples/summarize_results_test_cases_waitlist.jl#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Results-by-Test-Cases-WAITLIST"><a class="docs-heading-anchor" href="#Results-by-Test-Cases-WAITLIST">Results by Test Cases - WAITLIST</a><a id="Results-by-Test-Cases-WAITLIST-1"></a><a class="docs-heading-anchor-permalink" href="#Results-by-Test-Cases-WAITLIST" title="Permalink"></a></h1><p>Preview of test cases on the waitlist, to be added to the main evaluation.</p><p>In this note, we preview each test case and highlight the highest the best performing model for it.</p><p>Reminder: The below scores are on a scale 0-100, where 100 is the best possible score and 0 means the generated code was not even parseable.</p><pre><code class="language-julia hljs"># Imports
using JuliaLLMLeaderboard
using CairoMakie, AlgebraOfGraphics
using MarkdownTables, DataFramesMeta, Markdown
using Statistics: mean, median, quantile;
unscrub_string(s::AbstractString) = split(s, &quot;_&quot;) .|&gt; titlecase |&gt; x -&gt; join(x, &quot; &quot;);

# ! Configuration
SAVE_PLOTS = false
DIR_RESULTS = joinpath(pkgdir(JuliaLLMLeaderboard), &quot;code_generation_waitlist&quot;)
PAID_MODELS_DEFAULT = [
    &quot;gpt-3.5-turbo&quot;,
    &quot;gpt-3.5-turbo-1106&quot;,
    &quot;gpt-3.5-turbo-0125&quot;,
    &quot;gpt-4-1106-preview&quot;,
    &quot;gpt-4-0125-preview&quot;,
    &quot;gpt-4o-2024-05-13&quot;,
    &quot;gpt-4o-mini-2024-07-18&quot;,
    &quot;gpt-4o-2024-08-06&quot;,
    &quot;mistral-tiny&quot;,
    &quot;mistral-small&quot;,
    &quot;mistral-medium&quot;,
    &quot;mistral-large&quot;,
    &quot;mistral-small-2402&quot;,
    &quot;mistral-medium-2312&quot;,
    &quot;mistral-large-2402&quot;,
    &quot;claude-3-opus-20240229&quot;,
    &quot;claude-3-sonnet-20240229&quot;,
    &quot;claude-3-haiku-20240307&quot;,
    &quot;claude-3-5-sonnet-20240620&quot;,
    &quot;gemini-1.0-pro-latest&quot;,
    &quot;deepseek-chat&quot;,
    &quot;deepseek-coder&quot;,
    &quot;codestral-2405&quot;,
    &quot;mistral-large-2407&quot;
];
PROMPTS = [
    &quot;JuliaExpertCoTTask&quot;,
    &quot;JuliaExpertAsk&quot;,
    &quot;InJulia&quot;,
    &quot;JuliaRecapTask&quot;,
    &quot;JuliaRecapCoTTask&quot;,
    &quot;JuliaExpertAskXML&quot;,
    &quot;JuliaExpertCoTTaskXML&quot;
];</code></pre><h2 id="Load-Results"><a class="docs-heading-anchor" href="#Load-Results">Load Results</a><a id="Load-Results-1"></a><a class="docs-heading-anchor-permalink" href="#Load-Results" title="Permalink"></a></h2><p>Use only the 5 most recent evaluations available for each definition/model/prompt</p><pre><code class="language-julia hljs">df = load_evals(DIR_RESULTS; max_history = 5);
fn_definitions = find_definitions(DIR_RESULTS);
</code></pre><p>There are currently 2 test cases.</p><h2 id="Tabular-Overview"><a class="docs-heading-anchor" href="#Tabular-Overview">Tabular Overview</a><a id="Tabular-Overview-1"></a><a class="docs-heading-anchor-permalink" href="#Tabular-Overview" title="Permalink"></a></h2><p>Overview of all test cases, sorted by average score and with the winning model highlighted (separated by Paid vs Open-Source)</p><pre><code class="language-julia hljs"># Pre-aggregate winning models
top_model = @chain df begin
    # remove qwen models as they are not correct!
    @rsubset !occursin(&quot;qwen&quot;, :model)
    @rsubset !endswith(:model, &quot;--optim&quot;)
    @by [:model, :name] :score=mean(:score)
    @rtransform :is_paid = :model in PAID_MODELS_DEFAULT
    @orderby -:score
    combine(first, groupby(_, [:name, :is_paid]))
    @rtransform :winner = &quot;$(:model) ($(round(:score;digits=1)))&quot;
    select(Not(:model, :score))
end
# Aggregate by test case
@chain df begin
    @rsubset :prompt_label in PROMPTS
    @by :name begin
        :average_score = mean(:score)
        :average_elapsed = mean(:elapsed_seconds)
        :count_zero_score = count(iszero, :score)
        :count_full_score = count(==(100), :score)
        :count_samples = $nrow
    end
    @rtransform :average_score=round(:average_score; digits = 1) :average_elapsed=round(
        :average_elapsed;
        digits = 1)
    leftjoin(_,
        @rsubset(top_model, :is_paid),
        on = [:name],
        validate = (true, true),
        makeunique = true)
    leftjoin(_,
        @rsubset(top_model, :is_paid==false),
        on = [:name],
        validate = (true, true),
        makeunique = true)
    select(Not(:is_paid, :is_paid_1))
    rename(:winner =&gt; :paid_winner, :winner_1 =&gt; :oss_winner)
    rename(_, names(_) .|&gt; unscrub_string)
end</code></pre><div><div style = "float: left;"><span>2×8 DataFrame</span></div><div style = "clear: both;"></div></div><div class = "data-frame" style = "overflow-x: scroll;"><table class = "data-frame" style = "margin-bottom: 6px;"><thead><tr class = "header"><th class = "rowNumber" style = "font-weight: bold; text-align: right;">Row</th><th style = "text-align: left;">Name</th><th style = "text-align: left;">Average Score</th><th style = "text-align: left;">Average Elapsed</th><th style = "text-align: left;">Count Zero Score</th><th style = "text-align: left;">Count Full Score</th><th style = "text-align: left;">Count Samples</th><th style = "text-align: left;">Paid Winner</th><th style = "text-align: left;">Oss Winner</th></tr><tr class = "subheader headerLastRow"><th class = "rowNumber" style = "font-weight: bold; text-align: right;"></th><th title = "String" style = "text-align: left;">String</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "Int64" style = "text-align: left;">Int64</th><th title = "Int64" style = "text-align: left;">Int64</th><th title = "Int64" style = "text-align: left;">Int64</th><th title = "Union{Missing, String}" style = "text-align: left;">String?</th><th title = "Union{Missing, String}" style = "text-align: left;">String?</th></tr></thead><tbody><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">1</td><td style = "text-align: left;">find_mean</td><td style = "text-align: right;">78.5</td><td style = "text-align: right;">16.3</td><td style = "text-align: right;">9</td><td style = "text-align: right;">104</td><td style = "text-align: right;">180</td><td style = "text-align: left;">mistral-small-2402 (91.7)</td><td style = "text-align: left;">codellama:13b (77.0)</td></tr><tr><td class = "rowNumber" style = "font-weight: bold; text-align: right;">2</td><td style = "text-align: left;">find_median</td><td style = "text-align: right;">61.6</td><td style = "text-align: right;">14.7</td><td style = "text-align: right;">8</td><td style = "text-align: right;">4</td><td style = "text-align: right;">180</td><td style = "text-align: left;">gpt-4-0125-preview (81.3)</td><td style = "text-align: left;">magicoder:7b-s-cl-q6_K (52.1)</td></tr></tbody></table></div><h2 id="Individual-Test-Cases"><a class="docs-heading-anchor" href="#Individual-Test-Cases">Individual Test Cases</a><a id="Individual-Test-Cases-1"></a><a class="docs-heading-anchor-permalink" href="#Individual-Test-Cases" title="Permalink"></a></h2><pre><code class="language-julia hljs">io = IOBuffer()
for fn in fn_definitions
    # fn = fn_definitions[1]
    d = load_definition(fn)[&quot;code_generation&quot;]

    println(io, &quot;### Test Case: $(&quot;`&quot;*(d[&quot;name&quot;])*&quot;`&quot;)&quot;)
    println(io)
    println(io, &quot;- Definition file: `$(relpath(fn,pkgdir(JuliaLLMLeaderboard)))`&quot;)
    println(io, &quot;- Prompt: \&quot;$(d[&quot;prompt&quot;])\&quot;&quot;)
    println(io, &quot;- Evaluation criteria: $(join(&quot;`&quot;.*d[&quot;criteria&quot;].*&quot;`&quot;,&quot;, &quot;))&quot;)
    println(io, &quot;- Allowed imports: $(join(d[&quot;imports&quot;],&quot;, &quot;))&quot;)
    println(io, &quot;- Defined examples: $(length(get(d,&quot;examples&quot;,[])))&quot;)
    println(io, &quot;- Defined unit tests: $(length(get(d,&quot;unit_tests&quot;,[])))&quot;)
    println(io, &quot;- Reference solution: \n\n`````julia\n$(d[&quot;reference_solution&quot;])\n`````\n&quot;)
    # Paid model winner
    winner = @chain df begin
        @rsubset :model in PAID_MODELS_DEFAULT &amp;&amp; :prompt_label in PROMPTS
        @rsubset :name == d[&quot;name&quot;]
        @by :model begin
            :score = mean(:score)
            :elapsed = mean(:elapsed_seconds)
            :count_zero_score = count(iszero, :score)
            :count_full_score = count(==(100), :score)
            :cnt = $nrow
        end
        @orderby -:score
        first
    end
    println(io,
        &quot;**Winning Paid Model:** \&quot;$(winner.model)\&quot; with average score $(round(winner.score;digits=1)) (Full score: $(winner.count_full_score)/$(winner.cnt), Zero score: $(winner.count_zero_score)/$(winner.cnt)) \n&quot;)
    # OSS winner
    # winner = @chain df begin
    #     @rsubset !any(startswith.(:model, PAID_MODELS_DEFAULT)) &amp;&amp; :prompt_label in PROMPTS
    #     @rsubset :name == d[&quot;name&quot;]
    #     @by :model begin
    #         :score = mean(:score)
    #         :elapsed = mean(:elapsed_seconds)
    #         :count_zero_score = count(iszero, :score)
    #         :count_full_score = count(==(100), :score)
    #         :cnt = $nrow
    #     end
    #     @orderby -:score
    #     first
    # end
    # println(io,
    #     &quot;**Winning Locally-hosted Model:** \&quot;$(winner.model)\&quot; with average score $(round(winner.score;digits=1)) (Full score: $(winner.count_full_score)/$(winner.cnt), Zero score: $(winner.count_zero_score)/$(winner.cnt)) \n&quot;)
    println(io, &quot;\n&quot;)
end
MD(String(take!(io)))</code></pre><h3 id="Test-Case:-find_mean"><a class="docs-heading-anchor" href="#Test-Case:-find_mean">Test Case: <code>find_mean</code></a><a id="Test-Case:-find_mean-1"></a><a class="docs-heading-anchor-permalink" href="#Test-Case:-find_mean" title="Permalink"></a></h3><ul><li>Definition file: <code>code_generation_waitlist/statistics/find_mean/definition.toml</code></li><li>Prompt: &quot;Write a function <code>find_mean</code>. It computes the weighted mean of array <code>A</code> with weight vector <code>w</code>. Provide an example&quot;</li><li>Evaluation criteria: <code>parsed</code>, <code>executed</code>, <code>passed_unit_tests</code>, <code>executed_examples</code></li><li>Allowed imports: Test</li><li>Defined examples: 4</li><li>Defined unit tests: 5</li><li>Reference solution: </li></ul><pre><code class="language-julia hljs">function find_mean(data::AbstractVector, weights::AbstractVector)
    @assert length(data) == length(weights) &quot;Data and weights must have the same length&quot;
    
    total_weight = sum(weights)
    @assert total_weight != 0 &quot;Total weight cannot be zero&quot;
    
    sum_product = sum(data .* weights)
    
    return sum_product / total_weight
end
</code></pre><p><strong>Winning Paid Model:</strong> &quot;mistral-small-2402&quot; with average score 91.7 (Full score: 21/25, Zero score: 0/25) </p><h3 id="Test-Case:-find_median"><a class="docs-heading-anchor" href="#Test-Case:-find_median">Test Case: <code>find_median</code></a><a id="Test-Case:-find_median-1"></a><a class="docs-heading-anchor-permalink" href="#Test-Case:-find_median" title="Permalink"></a></h3><ul><li>Definition file: <code>code_generation_waitlist/statistics/find_median/definition.toml</code></li><li>Prompt: &quot;Write a function <code>find</code>. It computes median over arbitrary array. Provide an example&quot;</li><li>Evaluation criteria: <code>parsed</code>, <code>executed</code>, <code>passed_unit_tests</code>, <code>executed_examples</code></li><li>Allowed imports: Test, Statistics</li><li>Defined examples: 4</li><li>Defined unit tests: 10</li><li>Reference solution: </li></ul><pre><code class="language-julia hljs">function find_median(v::AbstractVector)
    isempty(v) &amp;&amp; throw(ArgumentError(&quot;median of an empty array is undefined.&quot;))
    eltype(v)&gt;:Missing &amp;&amp; any(ismissing, v) &amp;&amp; return missing
    any(x -&gt; x isa Number &amp;&amp; isnan(x), v) &amp;&amp; return convert(eltype(v), NaN)
    inds = axes(v, 1)
    n = length(inds)
    mid = div(first(inds)+last(inds),2)
    if isodd(n)
        return middle(partialsort!(v,mid))
    else
        m = partialsort!(v, mid:mid+1)
        return middle(m[1], m[2])
    end
end
</code></pre><p><strong>Winning Paid Model:</strong> &quot;gpt-4-0125-preview&quot; with average score 81.3 (Full score: 1/25, Zero score: 1/25) </p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.5.0 on <span class="colophon-date" title="Wednesday 7 August 2024 08:36">Wednesday 7 August 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
